{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-08-23T16:48:23.420280Z",
     "iopub.status.busy": "2020-08-23T16:48:23.419634Z",
     "iopub.status.idle": "2020-08-23T16:48:23.431848Z",
     "shell.execute_reply": "2020-08-23T16:48:23.432571Z"
    },
    "papermill": {
     "duration": 0.029624,
     "end_time": "2020-08-23T16:48:23.432783",
     "exception": false,
     "start_time": "2020-08-23T16:48:23.403159",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/janatahack-independence-day-2020-ml-hackathon/sample_submission_UVKGLZE.csv\n",
      "/kaggle/input/janatahack-independence-day-2020-ml-hackathon/train.csv\n",
      "/kaggle/input/janatahack-independence-day-2020-ml-hackathon/test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.010804,
     "end_time": "2020-08-23T16:48:23.454962",
     "exception": false,
     "start_time": "2020-08-23T16:48:23.444158",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Necessary Import Statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-23T16:48:23.489358Z",
     "iopub.status.busy": "2020-08-23T16:48:23.488595Z",
     "iopub.status.idle": "2020-08-23T16:48:32.514363Z",
     "shell.execute_reply": "2020-08-23T16:48:32.512670Z"
    },
    "papermill": {
     "duration": 9.049261,
     "end_time": "2020-08-23T16:48:32.514510",
     "exception": false,
     "start_time": "2020-08-23T16:48:23.465249",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from tqdm import tqdm\n",
    "import transformers\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "words = stopwords.words(\"english\")\n",
    "lemma = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "\n",
    "import torch\n",
    "from transformers import BertTokenizer\n",
    "from transformers import RobertaTokenizer\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import BertModel,RobertaModel\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "import random\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-23T16:48:32.554090Z",
     "iopub.status.busy": "2020-08-23T16:48:32.553438Z",
     "iopub.status.idle": "2020-08-23T16:48:33.485435Z",
     "shell.execute_reply": "2020-08-23T16:48:33.484600Z"
    },
    "papermill": {
     "duration": 0.95973,
     "end_time": "2020-08-23T16:48:33.485557",
     "exception": false,
     "start_time": "2020-08-23T16:48:32.525827",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('/kaggle/input/janatahack-independence-day-2020-ml-hackathon/train.csv')\n",
    "test = pd.read_csv('/kaggle/input/janatahack-independence-day-2020-ml-hackathon/test.csv')\n",
    "sub = pd.read_csv('/kaggle/input/janatahack-independence-day-2020-ml-hackathon/sample_submission_UVKGLZE.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-23T16:48:33.515181Z",
     "iopub.status.busy": "2020-08-23T16:48:33.514291Z",
     "iopub.status.idle": "2020-08-23T16:48:33.518014Z",
     "shell.execute_reply": "2020-08-23T16:48:33.518532Z"
    },
    "papermill": {
     "duration": 0.021696,
     "end_time": "2020-08-23T16:48:33.518651",
     "exception": false,
     "start_time": "2020-08-23T16:48:33.496955",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'TITLE', 'ABSTRACT', 'Computer Science', 'Physics', 'Mathematics',\n",
       "       'Statistics', 'Quantitative Biology', 'Quantitative Finance'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-23T16:48:33.546701Z",
     "iopub.status.busy": "2020-08-23T16:48:33.544729Z",
     "iopub.status.idle": "2020-08-23T16:48:33.547495Z",
     "shell.execute_reply": "2020-08-23T16:48:33.547996Z"
    },
    "papermill": {
     "duration": 0.018431,
     "end_time": "2020-08-23T16:48:33.548107",
     "exception": false,
     "start_time": "2020-08-23T16:48:33.529676",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "targets = ['ComputerScience', 'Physics', 'Mathematics','Statistics', 'QuantitativeBiology', 'QuantitativeFinance']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.010374,
     "end_time": "2020-08-23T16:48:33.568933",
     "exception": false,
     "start_time": "2020-08-23T16:48:33.558559",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "As it is a multilabel classification problem there will be muliple targets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-23T16:48:33.598367Z",
     "iopub.status.busy": "2020-08-23T16:48:33.597553Z",
     "iopub.status.idle": "2020-08-23T16:48:33.652701Z",
     "shell.execute_reply": "2020-08-23T16:48:33.651506Z"
    },
    "papermill": {
     "duration": 0.073424,
     "end_time": "2020-08-23T16:48:33.652836",
     "exception": false,
     "start_time": "2020-08-23T16:48:33.579412",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train[\"text\"] = train[\"TITLE\"]+\"\"+train[\"ABSTRACT\"]\n",
    "test[\"text\"] = test[\"TITLE\"]+\"\"+test[\"ABSTRACT\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.010838,
     "end_time": "2020-08-23T16:48:33.675207",
     "exception": false,
     "start_time": "2020-08-23T16:48:33.664369",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Combining the Title and Abstract of the given data to create a final text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-23T16:48:33.706752Z",
     "iopub.status.busy": "2020-08-23T16:48:33.706167Z",
     "iopub.status.idle": "2020-08-23T16:48:33.719772Z",
     "shell.execute_reply": "2020-08-23T16:48:33.720557Z"
    },
    "papermill": {
     "duration": 0.034471,
     "end_time": "2020-08-23T16:48:33.720686",
     "exception": false,
     "start_time": "2020-08-23T16:48:33.686215",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = train.text.values\n",
    "y = train[['Computer Science', 'Physics', 'Mathematics',\n",
    "       'Statistics', 'Quantitative Biology', 'Quantitative Finance']].values\n",
    "\n",
    "X_train, X_val, y_train, y_val =train_test_split(X, y, test_size=0.1, random_state=2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.010602,
     "end_time": "2020-08-23T16:48:33.742349",
     "exception": false,
     "start_time": "2020-08-23T16:48:33.731747",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Performing train test split on all the target column value as Y and our combined text as X Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-23T16:48:34.125672Z",
     "iopub.status.busy": "2020-08-23T16:48:34.119273Z",
     "iopub.status.idle": "2020-08-23T16:48:34.132220Z",
     "shell.execute_reply": "2020-08-23T16:48:34.132849Z"
    },
    "papermill": {
     "duration": 0.380081,
     "end_time": "2020-08-23T16:48:34.133312",
     "exception": false,
     "start_time": "2020-08-23T16:48:33.753231",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "Device name: Tesla P100-PCIE-16GB\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():       \n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
    "    print('Device name:', torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.011314,
     "end_time": "2020-08-23T16:48:34.156610",
     "exception": false,
     "start_time": "2020-08-23T16:48:34.145296",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Check which device we are using Either GPU OR CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-23T16:48:34.184469Z",
     "iopub.status.busy": "2020-08-23T16:48:34.183667Z",
     "iopub.status.idle": "2020-08-23T16:48:34.186920Z",
     "shell.execute_reply": "2020-08-23T16:48:34.187472Z"
    },
    "papermill": {
     "duration": 0.019943,
     "end_time": "2020-08-23T16:48:34.187595",
     "exception": false,
     "start_time": "2020-08-23T16:48:34.167652",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def text_preprocessing(text):\n",
    "#     \"\"\"\n",
    "#     - Remove entity mentions (eg. '@united')\n",
    "#     - Correct errors (eg. '&amp;' to '&')\n",
    "#     @param    text (str): a string to be processed.\n",
    "#     @return   text (Str): the processed string.\n",
    "#     \"\"\"\n",
    "#     text = text.lower()\n",
    "#     text = re.sub(r\"what's\", \"what is \", text)\n",
    "#     text = re.sub(r\"won't\", \"will not \", text)\n",
    "#     text = re.sub(r\"\\'s\", \" \", text)\n",
    "#     text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "#     text = re.sub(r\"can't\", \"can not \", text)\n",
    "#     text = re.sub(r\"n't\", \" not \", text)\n",
    "#     text = re.sub(r\"i'm\", \"i am \", text)\n",
    "#     text = re.sub(r\"\\'re\", \" are \", text)\n",
    "#     text = re.sub(r\"\\'d\", \" would \", text)\n",
    "#     text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "#     text = re.sub(r\"\\'scuse\", \" excuse \", text)\n",
    "#     text = re.sub(r\"\\'\\n\", \" \", text)\n",
    "#     text = re.sub(r\"-\", \" \", text)\n",
    "#     text = re.sub(r\"\\'\\xa0\", \" \", text)\n",
    "#     text = re.sub('\\s+', ' ', text)\n",
    "#     text = ''.join(c for c in text if not c.isnumeric())\n",
    "    \n",
    "#     # Remove '@name'\n",
    "#     text = re.sub(r'(@.*?)[\\s]', ' ', text)\n",
    "    \n",
    "      # Remove Latex tags in the test\n",
    "#     text = re.sub(r'(\\$+)(?:(?!\\1)[\\s\\S])*\\1',' ',text)\n",
    "    \n",
    "      # Remove words with in brackets\n",
    "#     text = re.sub(r'\\([^)]*\\)', '', text)\n",
    "\n",
    "#     # Replace '&amp;' with '&'\n",
    "#     text = re.sub(r'&amp;', '&', text)\n",
    "\n",
    "#     # Remove trailing whitespace\n",
    "#     text = re.sub(r'\\s+', ' ', text).strip()\n",
    "     \n",
    "# #     tokens = word_tokenize(text)\n",
    "# #     remove_words = [word for word in tokens if not word in words]\n",
    "# #     text = [lemma.lemmatize(word) for word in remove_words]\n",
    "# #     joined_words = \" \".join(text)\n",
    "\n",
    "#     return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-23T16:48:34.226583Z",
     "iopub.status.busy": "2020-08-23T16:48:34.222772Z",
     "iopub.status.idle": "2020-08-23T16:48:34.229578Z",
     "shell.execute_reply": "2020-08-23T16:48:34.229026Z"
    },
    "papermill": {
     "duration": 0.030974,
     "end_time": "2020-08-23T16:48:34.229680",
     "exception": false,
     "start_time": "2020-08-23T16:48:34.198706",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def text_preprocessing(text):\n",
    "    \"\"\"\n",
    "    - Remove entity mentions (eg. '@united')\n",
    "    - Correct errors (eg. '&amp;' to '&')\n",
    "    @param    text (str): a string to be processed.\n",
    "    @return   text (Str): the processed string.\n",
    "    \"\"\"\n",
    "    \n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"won't\", \"will not \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"can not \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\"\\'scuse\", \" excuse \", text)\n",
    "    text = re.sub(r\"\\'\\n\", \" \", text)\n",
    "    text = re.sub(r\"-\", \" \", text)\n",
    "    text = re.sub(r\"\\'\\xa0\", \" \", text)\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    text = ''.join(c for c in text if not c.isnumeric())\n",
    "    \n",
    "    # Remove '@name'\n",
    "    text = re.sub(r'(@.*?)[\\s]', ' ', text)\n",
    "\n",
    "    # Replace '&amp;' with '&'\n",
    "    text = re.sub(r'&amp;', '&', text)\n",
    "\n",
    "    # Remove trailing whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.010586,
     "end_time": "2020-08-23T16:48:34.251486",
     "exception": false,
     "start_time": "2020-08-23T16:48:34.240900",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "General Pre-Processing Steps to remove unwnated characters extrac spaces and other simple steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-23T16:48:34.280834Z",
     "iopub.status.busy": "2020-08-23T16:48:34.279954Z",
     "iopub.status.idle": "2020-08-23T16:48:34.288478Z",
     "shell.execute_reply": "2020-08-23T16:48:34.287790Z"
    },
    "papermill": {
     "duration": 0.026105,
     "end_time": "2020-08-23T16:48:34.288597",
     "exception": false,
     "start_time": "2020-08-23T16:48:34.262492",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistical Latent Space Approach for Mixed Data Modelling and Applications  The analysis of mixed data has been raising challenges in statistics and\n",
      "machine learning. One of two most prominent challenges is to develop new\n",
      "statistical techniques and methodologies to effectively handle mixed data by\n",
      "making the data less heterogeneous with minimum loss of information. The other\n",
      "challenge is that such methods must be able to apply in large-scale tasks when\n",
      "dealing with huge amount of mixed data. To tackle these challenges, we\n",
      "introduce parameter sharing and balancing extensions to our recent model, the\n",
      "mixed-variate restricted Boltzmann machine (MV.RBM) which can transform\n",
      "heterogeneous data into homogeneous representation. We also integrate\n",
      "structured sparsity and distance metric learning into RBM-based models. Our\n",
      "proposed methods are applied in various applications including latent patient\n",
      "profile modelling in medical data analysis and representation learning for\n",
      "image retrieval. The experimental results demonstrate the models perform better\n",
      "than baseline methods in medical data and outperform state-of-the-art rivals in\n",
      "image dataset.\n",
      "\n",
      "statistical latent space approach for mixed data modelling and applications the analysis of mixed data has been raising challenges in statistics and machine learning. one of two most prominent challenges is to develop new statistical techniques and methodologies to effectively handle mixed data by making the data less heterogeneous with minimum loss of information. the other challenge is that such methods must be able to apply in large scale tasks when dealing with huge amount of mixed data. to tackle these challenges, we introduce parameter sharing and balancing extensions to our recent model, the mixed variate restricted boltzmann machine (mv.rbm) which can transform heterogeneous data into homogeneous representation. we also integrate structured sparsity and distance metric learning into rbm based models. our proposed methods are applied in various applications including latent patient profile modelling in medical data analysis and representation learning for image retrieval. the experimental results demonstrate the models perform better than baseline methods in medical data and outperform state of the art rivals in image dataset.\n"
     ]
    }
   ],
   "source": [
    "temp = train[\"text\"][1000]\n",
    "print(temp)\n",
    "val = text_preprocessing(text=temp)\n",
    "print(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-23T16:48:34.330238Z",
     "iopub.status.busy": "2020-08-23T16:48:34.329246Z",
     "iopub.status.idle": "2020-08-23T16:48:35.364508Z",
     "shell.execute_reply": "2020-08-23T16:48:35.365399Z"
    },
    "papermill": {
     "duration": 1.059339,
     "end_time": "2020-08-23T16:48:35.365586",
     "exception": false,
     "start_time": "2020-08-23T16:48:34.306247",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1945f80ae1c04c24932f188369ae47d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Load the Bert tokenizer\n",
    "# tokenizer = RobertaTokenizer.from_pretrained('roberta-base',do_lower_case=True)\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\",do_lower_case=True)\n",
    "# Create a funcition to tokenize a set of text\n",
    "\n",
    "def preprocessing_for_bert(data):\n",
    "    \"\"\"Perform required preprocessing steps for pretrained BERT.\n",
    "    @param    data (np.array): Array of texts to be processed.\n",
    "    @return   input_ids (torch.Tensor): Tensor of token ids to be fed to a model.\n",
    "    @return   attention_masks (torch.Tensor): Tensor of indices specifying which\n",
    "                  tokens should be attended to by the model.\n",
    "    \"\"\"\n",
    "    # create empty lists to store outputs\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    \n",
    "    #for every sentence...\n",
    "    \n",
    "    for sent in data:\n",
    "        # 'encode_plus will':\n",
    "        # (1) Tokenize the sentence\n",
    "        # (2) Add the `[CLS]` and `[SEP]` token to the start and end\n",
    "        # (3) Truncate/Pad sentence to max length\n",
    "        # (4) Map tokens to their IDs\n",
    "        # (5) Create attention mask\n",
    "        # (6) Return a dictionary of outputs\n",
    "        encoded_sent = tokenizer.encode_plus(\n",
    "            text = text_preprocessing(sent),   #preprocess sentence\n",
    "            add_special_tokens = True,         #Add `[CLS]` and `[SEP]`\n",
    "            max_length= MAX_LEN  ,             #Max length to truncate/pad\n",
    "            pad_to_max_length = True,          #pad sentence to max length \n",
    "            return_attention_mask= True        #Return attention mask \n",
    "        )\n",
    "        # Add the outputs to the lists\n",
    "        input_ids.append(encoded_sent.get('input_ids'))\n",
    "        attention_masks.append(encoded_sent.get('attention_mask'))\n",
    "        \n",
    "    #convert lists to tensors\n",
    "    input_ids = torch.tensor(input_ids)\n",
    "    attention_masks = torch.tensor(attention_masks)\n",
    "    \n",
    "    return input_ids,attention_masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.011408,
     "end_time": "2020-08-23T16:48:35.389073",
     "exception": false,
     "start_time": "2020-08-23T16:48:35.377665",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Pre Processing the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-23T16:48:35.470039Z",
     "iopub.status.busy": "2020-08-23T16:48:35.449502Z",
     "iopub.status.idle": "2020-08-23T16:48:47.566030Z",
     "shell.execute_reply": "2020-08-23T16:48:47.566669Z"
    },
    "papermill": {
     "duration": 12.166095,
     "end_time": "2020-08-23T16:48:47.566872",
     "exception": false,
     "start_time": "2020-08-23T16:48:35.400777",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg length:  1074.2067354227163\n"
     ]
    }
   ],
   "source": [
    "# Before tokenizing we need to specify the maximum length of our sentences\n",
    "\n",
    "#concat the train data and test data\n",
    "\n",
    "all_text = np.concatenate([train.text.values,test.text.values])\n",
    "\n",
    "#Encode the concatenated data\n",
    "len_sent = [len(text_preprocessing(sent)) for sent in all_text]\n",
    "\n",
    "# Find the maximum length\n",
    "avg_len = np.mean(len_sent)\n",
    "print('Avg length: ',avg_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-23T16:48:47.613563Z",
     "iopub.status.busy": "2020-08-23T16:48:47.608673Z",
     "iopub.status.idle": "2020-08-23T16:48:47.623718Z",
     "shell.execute_reply": "2020-08-23T16:48:47.624295Z"
    },
    "papermill": {
     "duration": 0.044942,
     "end_time": "2020-08-23T16:48:47.624430",
     "exception": false,
     "start_time": "2020-08-23T16:48:47.579488",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  Reconstructing Subject-Specific Effect Maps  Predictive models allow subject-specific inference when analyzing disease\n",
      "related alterations in neuroimaging data. Given a subject's data, inference can\n",
      "be made at two levels: global, i.e. identifiying condition presence for the\n",
      "subject, and local, i.e. detecting condition effect on each individual\n",
      "measurement extracted from the subject's data. While global inference is widely\n",
      "used, local inference, which can be used to form subject-specific effect maps,\n",
      "is rarely used because existing models often yield noisy detections composed of\n",
      "dispersed isolated islands. In this article, we propose a reconstruction\n",
      "method, named RSM, to improve subject-specific detections of predictive\n",
      "modeling approaches and in particular, binary classifiers. RSM specifically\n",
      "aims to reduce noise due to sampling error associated with using a finite\n",
      "sample of examples to train classifiers. The proposed method is a wrapper-type\n",
      "algorithm that can be used with different binary classifiers in a diagnostic\n",
      "manner, i.e. without information on condition presence. Reconstruction is posed\n",
      "as a Maximum-A-Posteriori problem with a prior model whose parameters are\n",
      "estimated from training data in a classifier-specific fashion. Experimental\n",
      "evaluation is performed on synthetically generated data and data from the\n",
      "Alzheimer's Disease Neuroimaging Initiative (ADNI) database. Results on\n",
      "synthetic data demonstrate that using RSM yields higher detection accuracy\n",
      "compared to using models directly or with bootstrap averaging. Analyses on the\n",
      "ADNI dataset show that RSM can also improve correlation between\n",
      "subject-specific detections in cortical thickness data and non-imaging markers\n",
      "of Alzheimer's Disease (AD), such as the Mini Mental State Examination Score\n",
      "and Cerebrospinal Fluid amyloid-$\\beta$ levels. Further reliability studies on\n",
      "the longitudinal ADNI dataset show improvement on detection reliability when\n",
      "RSM is used.\n",
      "\n",
      "Token IDs:  [101, 28667, 5644, 26310, 3395, 3563, 3466, 7341, 16014, 3512, 4275, 3499, 3395, 3563, 28937, 2043, 20253, 4295, 3141, 16705, 1999, 11265, 10976, 9581, 4726, 2951, 1012, 2445, 1037, 3395, 2951, 1010, 28937, 2064, 2022, 2081, 2012, 2048, 3798, 1024, 3795, 1010, 1045, 1012, 1041, 1012, 8909, 4765, 10128, 28008, 2075, 4650, 3739, 2005, 1996, 3395, 1010, 1998, 2334, 1010, 1045, 1012, 1041, 1012, 25952, 4650, 3466, 2006, 2169, 3265, 10903, 15901, 2013, 1996, 3395, 2951, 1012, 2096, 3795, 28937, 2003, 4235, 2109, 1010, 2334, 28937, 1010, 2029, 2064, 2022, 2109, 2000, 2433, 3395, 3563, 3466, 7341, 1010, 2003, 6524, 2109, 2138, 4493, 4275, 2411, 10750, 20810, 10788, 2015, 3605, 1997, 15484, 7275, 3470, 1012, 1999, 2023, 3720, 1010, 2057, 16599, 1037, 8735, 4118, 1010, 2315, 12667, 2213, 1010, 2000, 5335, 3395, 3563, 10788, 2015, 1997, 16014, 3512, 11643, 8107, 1998, 1999, 3327, 1010, 12441, 2465, 28295, 1012, 12667, 2213, 4919, 8704, 2000, 5547, 5005, 2349, 2000, 16227, 7561, 3378, 2007, 2478, 1037, 10713, 7099, 1997, 4973, 2000, 3345, 2465, 28295, 1012, 1996, 3818, 4118, 2003, 1037, 10236, 4842, 2828, 9896, 2008, 2064, 2022, 2109, 2007, 2367, 12441, 2465, 28295, 1999, 1037, 16474, 5450, 1010, 1045, 1012, 1041, 1012, 2302, 2592, 2006, 4650, 3739, 1012, 8735, 2003, 13686, 2004, 1037, 4555, 1037, 15219, 2072, 3291, 2007, 1037, 3188, 2944, 3005, 11709, 2024, 4358, 2013, 2731, 2951, 1999, 1037, 2465, 18095, 3563, 4827, 1012, 6388, 9312, 2003, 2864, 2006, 12553, 3973, 7013, 2951, 1998, 2951, 2013, 1996, 21901, 4295, 11265, 10976, 9581, 4726, 6349, 1006, 4748, 3490, 1007, 7809, 1012, 3463, 2006, 12553, 2951, 10580, 2008, 2478, 12667, 2213, 16189, 3020, 10788, 10640, 4102, 2000, 2478, 4275, 3495, 2030, 2007, 6879, 6494, 2361, 14985, 1012, 16478, 2006, 1996, 4748, 3490, 2951, 13462, 2265, 2008, 12667, 2213, 2064, 2036, 5335, 16902, 2090, 3395, 3563, 10788, 2015, 1999, 2522, 28228, 9289, 14983, 2951, 1998, 2512, 12126, 16387, 1997, 21901, 4295, 1006, 4748, 1007, 1010, 2107, 2004, 1996, 7163, 5177, 2110, 7749, 3556, 1998, 8292, 2890, 12618, 13102, 13290, 8331, 6864, 27710, 1002, 1032, 8247, 1002, 3798, 1012, 2582, 15258, 2913, 2006, 1996, 20134, 4748, 3490, 2951, 13462, 2265, 7620, 2006, 10788, 15258, 2043, 12667, 2213, 2003, 2109, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "## Now Tokenizing the data\n",
    "\n",
    "MAX_LEN = 500\n",
    "\n",
    "# Print sentece 0 and its encoded token ids\n",
    "token_ids = list(preprocessing_for_bert([X[0]])[0].squeeze().numpy())\n",
    "print('Original: ',X[0])\n",
    "print('Token IDs: ',token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-23T16:48:47.666829Z",
     "iopub.status.busy": "2020-08-23T16:48:47.661671Z",
     "iopub.status.idle": "2020-08-23T16:51:39.079379Z",
     "shell.execute_reply": "2020-08-23T16:51:39.078769Z"
    },
    "papermill": {
     "duration": 171.443232,
     "end_time": "2020-08-23T16:51:39.079515",
     "exception": false,
     "start_time": "2020-08-23T16:48:47.636283",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing data...\n"
     ]
    }
   ],
   "source": [
    "# Run function 'preprocessing_for_bert' on the train set and validation set\n",
    "print('Tokenizing data...')\n",
    "train_inputs, train_masks = preprocessing_for_bert(X_train)\n",
    "val_inputs, val_masks = preprocessing_for_bert(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-23T16:51:39.113751Z",
     "iopub.status.busy": "2020-08-23T16:51:39.112942Z",
     "iopub.status.idle": "2020-08-23T16:51:39.124092Z",
     "shell.execute_reply": "2020-08-23T16:51:39.123565Z"
    },
    "papermill": {
     "duration": 0.032001,
     "end_time": "2020-08-23T16:51:39.124210",
     "exception": false,
     "start_time": "2020-08-23T16:51:39.092209",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert other data types to torch.Tensor\n",
    "train_labels = torch.tensor(y_train)\n",
    "val_labels = torch.tensor(y_val)\n",
    "\n",
    "## For fine-tuning Bert, the authors recommmend a batch size of 16 or 32\n",
    "batch_size = 16\n",
    "\n",
    "# Create the DataLoader for our training set\n",
    "train_data = TensorDataset(train_inputs,train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# Create the DataLoader for our validation set\n",
    "val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
    "val_sampler = SequentialSampler(val_data)\n",
    "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.011835,
     "end_time": "2020-08-23T16:51:39.148938",
     "exception": false,
     "start_time": "2020-08-23T16:51:39.137103",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Creating the torch Data Loader for our train and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-23T16:51:39.181772Z",
     "iopub.status.busy": "2020-08-23T16:51:39.180950Z",
     "iopub.status.idle": "2020-08-23T16:51:39.184811Z",
     "shell.execute_reply": "2020-08-23T16:51:39.185466Z"
    },
    "papermill": {
     "duration": 0.024881,
     "end_time": "2020-08-23T16:51:39.185589",
     "exception": false,
     "start_time": "2020-08-23T16:51:39.160708",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 35 µs, sys: 0 ns, total: 35 µs\n",
      "Wall time: 39.1 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create the BertClassifier class\n",
    "\n",
    "class BertClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "        Bert Model for classification Tasks.\n",
    "    \"\"\"\n",
    "    def __init__(self, freeze_bert=False):\n",
    "        \"\"\"\n",
    "        @param   bert: a BertModel object\n",
    "        @param   classifier: a torch.nn.Module classifier\n",
    "        @param   freeze_bert (bool): Set `False` to fine_tune the Bert model\n",
    "        \"\"\"\n",
    "        super(BertClassifier,self).__init__()\n",
    "        # Specify hidden size of Bert, hidden size of our classifier, and number of labels\n",
    "        D_in, H,D_out = 768,30,6\n",
    "        \n",
    "#         self.bert = RobertaModel.from_pretrained('roberta-base')\n",
    "        self.bert = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "                            nn.Linear(D_in, H),\n",
    "                            nn.ReLU(),\n",
    "                            nn.Linear(H, D_out))\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        # Freeze the Bert Model\n",
    "        if freeze_bert:\n",
    "            for param in self.bert.parameters():\n",
    "                param.requires_grad = False\n",
    "    \n",
    "    def forward(self,input_ids,attention_mask):\n",
    "        \"\"\"\n",
    "        Feed input to BERT and the classifier to compute logits.\n",
    "        @param    input_ids (torch.Tensor): an input tensor with shape (batch_size,\n",
    "                      max_length)\n",
    "        @param    attention_mask (torch.Tensor): a tensor that hold attention mask\n",
    "                      information with shape (batch_size, max_length)\n",
    "        @return   logits (torch.Tensor): an output tensor with shape (batch_size,\n",
    "                      num_labels)\n",
    "        \"\"\"\n",
    "        outputs = self.bert(input_ids=input_ids,\n",
    "                           attention_mask = attention_mask)\n",
    "        \n",
    "        # Extract the last hidden state of the token `[CLS]` for classification task\n",
    "        last_hidden_state_cls = outputs[0][:,0,:]\n",
    "        \n",
    "        # Feed input to classifier to compute logits\n",
    "        logit = self.classifier(last_hidden_state_cls)\n",
    "        \n",
    "#         logits = self.sigmoid(logit)\n",
    "        \n",
    "        return logit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.011323,
     "end_time": "2020-08-23T16:51:39.208357",
     "exception": false,
     "start_time": "2020-08-23T16:51:39.197034",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Simple Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-23T16:51:39.239288Z",
     "iopub.status.busy": "2020-08-23T16:51:39.238427Z",
     "iopub.status.idle": "2020-08-23T16:51:39.241529Z",
     "shell.execute_reply": "2020-08-23T16:51:39.240822Z"
    },
    "papermill": {
     "duration": 0.02146,
     "end_time": "2020-08-23T16:51:39.241635",
     "exception": false,
     "start_time": "2020-08-23T16:51:39.220175",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def initialize_model(epochs=4):\n",
    "    \"\"\"Initialize the Bert Classifier, the optimizer and the learning rate scheduler.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Instantiate Bert Classifier\n",
    "    bert_classifier = BertClassifier(freeze_bert=False)\n",
    "    \n",
    "    bert_classifier.to(device)\n",
    "    \n",
    "    # Create the optimizer\n",
    "    optimizer = AdamW(bert_classifier.parameters(),\n",
    "                     lr=5e-5, #Default learning rate\n",
    "                     eps=1e-8 #Default epsilon value\n",
    "                     )\n",
    "    \n",
    "    # Total number of training steps\n",
    "    total_steps = len(train_dataloader) * epochs\n",
    "    \n",
    "    # Set up the learning rate scheduler\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                              num_warmup_steps=0, # Default value\n",
    "                                              num_training_steps=total_steps)\n",
    "    return bert_classifier, optimizer, scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.01117,
     "end_time": "2020-08-23T16:51:39.264535",
     "exception": false,
     "start_time": "2020-08-23T16:51:39.253365",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Specify the optimizer of our model with how many epochs you are going to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-23T16:51:39.306582Z",
     "iopub.status.busy": "2020-08-23T16:51:39.296240Z",
     "iopub.status.idle": "2020-08-23T16:51:39.324182Z",
     "shell.execute_reply": "2020-08-23T16:51:39.324648Z"
    },
    "papermill": {
     "duration": 0.048622,
     "end_time": "2020-08-23T16:51:39.324767",
     "exception": false,
     "start_time": "2020-08-23T16:51:39.276145",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Specify loss function\n",
    "#loss_fn = nn.CrossEntropyLoss()\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "def set_seed(seed_value=42):\n",
    "    \"\"\"Set seed for reproducibility.\n",
    "    \"\"\"\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed_all(seed_value)\n",
    "\n",
    "def train(model, train_dataloader, val_dataloader=None, epochs=4, evaluation=False):\n",
    "    \"\"\"Train the BertClassifier model.\n",
    "    \"\"\"\n",
    "    # Start training loop\n",
    "    print(\"Start training...\\n\")\n",
    "    for epoch_i in range(epochs):\n",
    "        # =======================================\n",
    "        #               Training\n",
    "        # =======================================\n",
    "        # Print the header of the result table\n",
    "        print(f\"{'Epoch':^7} | {'Batch':^7} | {'Train Loss':^12} | {'Val Loss':^10} | {'Val Acc':^9} | {'Elapsed':^9}\")\n",
    "        print(\"-\"*70)\n",
    "\n",
    "        # Measure the elapsed time of each epoch\n",
    "        t0_epoch, t0_batch = time.time(), time.time()\n",
    "\n",
    "        # Reset tracking variables at the beginning of each epoch\n",
    "        total_loss, batch_loss, batch_counts = 0, 0, 0\n",
    "\n",
    "        # Put the model into the training mode\n",
    "        model.train()\n",
    "\n",
    "        # For each batch of training data...\n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "            batch_counts +=1\n",
    "            # Load batch to GPU\n",
    "            b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
    "\n",
    "            # Zero out any previously calculated gradients\n",
    "            model.zero_grad()\n",
    "\n",
    "            # Perform a forward pass. This will return logits.\n",
    "            logits = model(b_input_ids, b_attn_mask)\n",
    "\n",
    "            # Compute loss and accumulate the loss values\n",
    "            loss = loss_fn(logits, b_labels.float())\n",
    "            batch_loss += loss.item()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Perform a backward pass to calculate gradients\n",
    "            loss.backward()\n",
    "\n",
    "            # Clip the norm of the gradients to 1.0 to prevent \"exploding gradients\"\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "            # Update parameters and the learning rate\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            # Print the loss values and time elapsed for every 20--50000 batches\n",
    "            if (step % 50000 == 0 and step != 0) or (step == len(train_dataloader) - 1):\n",
    "                # Calculate time elapsed for 20 batches\n",
    "                time_elapsed = time.time() - t0_batch\n",
    "\n",
    "                # Print training results\n",
    "                print(f\"{epoch_i + 1:^7} | {step:^7} | {batch_loss / batch_counts:^12.6f} | {'-':^10} | {'-':^9} | {time_elapsed:^9.2f}\")\n",
    "\n",
    "                # Reset batch tracking variables\n",
    "                batch_loss, batch_counts = 0, 0\n",
    "                t0_batch = time.time()\n",
    "\n",
    "        # Calculate the average loss over the entire training data\n",
    "        avg_train_loss = total_loss / len(train_dataloader)\n",
    "\n",
    "        print(\"-\"*70)\n",
    "        # =======================================\n",
    "        #               Evaluation\n",
    "        # =======================================\n",
    "        if evaluation == True:\n",
    "            # After the completion of each training epoch, measure the model's performance\n",
    "            # on our validation set.\n",
    "            val_loss, val_accuracy = evaluate(model, val_dataloader)\n",
    "\n",
    "            # Print performance over the entire training data\n",
    "            time_elapsed = time.time() - t0_epoch\n",
    "            \n",
    "            print(f\"{epoch_i + 1:^7} | {'-':^7} | {avg_train_loss:^12.6f} | {val_loss:^10.6f} | {val_accuracy:^9.2f} | {time_elapsed:^9.2f}\")\n",
    "            print(\"-\"*70)\n",
    "        print(\"\\n\")\n",
    "    \n",
    "    print(\"Training complete!\")\n",
    "\n",
    "\n",
    "def evaluate(model, val_dataloader):\n",
    "    \"\"\"After the completion of each training epoch, measure the model's performance\n",
    "    on our validation set.\n",
    "    \"\"\"\n",
    "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
    "    # the test time.\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables\n",
    "    val_accuracy = []\n",
    "    val_loss = []\n",
    "\n",
    "    # For each batch in our validation set...\n",
    "    for batch in val_dataloader:\n",
    "        # Load batch to GPU\n",
    "        b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
    "\n",
    "        # Compute logits\n",
    "        with torch.no_grad():\n",
    "            logits = model(b_input_ids, b_attn_mask)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = loss_fn(logits, b_labels.float())\n",
    "        val_loss.append(loss.item())\n",
    "\n",
    "        # Get the predictions\n",
    "        #preds = torch.argmax(logits, dim=1).flatten()\n",
    "        \n",
    "        # Calculate the accuracy rate\n",
    "        #accuracy = (preds == b_labels).cpu().numpy().mean() * 100\n",
    "        accuracy = accuracy_thresh(logits.view(-1,6),b_labels.view(-1,6))\n",
    "        \n",
    "        val_accuracy.append(accuracy)\n",
    "\n",
    "    # Compute the average accuracy and loss over the validation set.\n",
    "    val_loss = np.mean(val_loss)\n",
    "    val_accuracy = np.mean(val_accuracy)\n",
    "\n",
    "    return val_loss, val_accuracy\n",
    "\n",
    "def accuracy_thresh(y_pred, y_true, thresh:float=0.5, sigmoid:bool=True):\n",
    "    \"Compute accuracy when `y_pred` and `y_true` are the same size.\"\n",
    "    if sigmoid: \n",
    "        y_pred = y_pred.sigmoid()\n",
    "    return ((y_pred>thresh)==y_true.byte()).float().mean().item()\n",
    "    #return np.mean(((y_pred>thresh).float()==y_true.float()).float().cpu().numpy(), axis=1).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.011684,
     "end_time": "2020-08-23T16:51:39.348441",
     "exception": false,
     "start_time": "2020-08-23T16:51:39.336757",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Train function and Evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-23T16:51:39.377110Z",
     "iopub.status.busy": "2020-08-23T16:51:39.376260Z",
     "iopub.status.idle": "2020-08-23T17:08:55.098334Z",
     "shell.execute_reply": "2020-08-23T17:08:55.099146Z"
    },
    "papermill": {
     "duration": 1035.739203,
     "end_time": "2020-08-23T17:08:55.099386",
     "exception": false,
     "start_time": "2020-08-23T16:51:39.360183",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb708fa4e5fa4ab39d18ff30bf66f3fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88a0200a9d3940d1857f0838fd66e512",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start training...\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   1    |  1179   |   0.238121   |     -      |     -     |  977.42  \n",
      "----------------------------------------------------------------------\n",
      "   1    |    -    |   0.238121   |  0.182980  |   0.93    |  1012.39 \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "set_seed(42)    # Set seed for reproducibility\n",
    "bert_classifier, optimizer, scheduler = initialize_model(epochs=1)\n",
    "train(bert_classifier, train_dataloader, val_dataloader, epochs=1, evaluation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.019036,
     "end_time": "2020-08-23T17:08:55.137073",
     "exception": false,
     "start_time": "2020-08-23T17:08:55.118037",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Calling our Model for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-23T17:08:55.186200Z",
     "iopub.status.busy": "2020-08-23T17:08:55.185425Z",
     "iopub.status.idle": "2020-08-23T17:08:55.188464Z",
     "shell.execute_reply": "2020-08-23T17:08:55.189094Z"
    },
    "papermill": {
     "duration": 0.033911,
     "end_time": "2020-08-23T17:08:55.189284",
     "exception": false,
     "start_time": "2020-08-23T17:08:55.155373",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def bert_predict(model, test_dataloader):\n",
    "    \"\"\"Perform a forward pass on the trained BERT model to predict probabilities\n",
    "    on the test set.\n",
    "    \"\"\"\n",
    "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
    "    # the test time.\n",
    "    model.eval()\n",
    "\n",
    "    all_logits = []\n",
    "\n",
    "    # For each batch in our test set...\n",
    "    for batch in test_dataloader:\n",
    "        # Load batch to GPU\n",
    "        b_input_ids, b_attn_mask = tuple(t.to(device) for t in batch)[:2]\n",
    "\n",
    "        # Compute logits\n",
    "        with torch.no_grad():\n",
    "            logits = model(b_input_ids, b_attn_mask)\n",
    "        all_logits.append(logits)\n",
    "    \n",
    "    # Concatenate logits from each batch\n",
    "    all_logits = torch.cat(all_logits, dim=0)\n",
    "\n",
    "    # Apply softmax to calculate probabilities\n",
    "    #probs = F.softmax(all_logits, dim=1).cpu().numpy()\n",
    "    probs = all_logits.sigmoid().cpu().numpy()\n",
    "    \n",
    "\n",
    "    return probs\n",
    "\n",
    "#probs = all_logits.sigmoid().cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.018682,
     "end_time": "2020-08-23T17:08:55.226799",
     "exception": false,
     "start_time": "2020-08-23T17:08:55.208117",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Function to predict on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-23T17:08:55.272929Z",
     "iopub.status.busy": "2020-08-23T17:08:55.271981Z",
     "iopub.status.idle": "2020-08-23T17:09:30.145953Z",
     "shell.execute_reply": "2020-08-23T17:09:30.144963Z"
    },
    "papermill": {
     "duration": 34.900501,
     "end_time": "2020-08-23T17:09:30.146086",
     "exception": false,
     "start_time": "2020-08-23T17:08:55.245585",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Compute predicted probabilities on the test set\n",
    "\n",
    "probs = bert_predict(bert_classifier,val_dataloader)\n",
    "\n",
    "# Evalueate the bert classifier\n",
    "\n",
    "# evaluate_roc(probs, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-23T17:09:30.182073Z",
     "iopub.status.busy": "2020-08-23T17:09:30.181368Z",
     "iopub.status.idle": "2020-08-23T18:22:09.858608Z",
     "shell.execute_reply": "2020-08-23T18:22:09.859424Z"
    },
    "papermill": {
     "duration": 4359.699668,
     "end_time": "2020-08-23T18:22:09.859660",
     "exception": false,
     "start_time": "2020-08-23T17:09:30.159992",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   1    |  1310   |   0.234509   |     -      |     -     |  1087.89 \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   2    |  1310   |   0.151012   |     -      |     -     |  1090.34 \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   3    |  1310   |   0.111963   |     -      |     -     |  1089.61 \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   4    |  1310   |   0.081972   |     -      |     -     |  1088.52 \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# Concatenate the train set and the validation set\n",
    "\n",
    "full_train_data = torch.utils.data.ConcatDataset([train_data, val_data])\n",
    "full_train_sampler = RandomSampler(full_train_data)\n",
    "full_train_dataloader = DataLoader(full_train_data, sampler=full_train_sampler, batch_size=batch_size)\n",
    "\n",
    "# Train the Bert Classifier on the entire training data\n",
    "set_seed(42)\n",
    "bert_classifier, optimizer, scheduler = initialize_model(epochs=4)\n",
    "train(bert_classifier, full_train_dataloader, epochs=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.013084,
     "end_time": "2020-08-23T18:22:09.892764",
     "exception": false,
     "start_time": "2020-08-23T18:22:09.879680",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "0.218901\n",
    "0.152067\n",
    "0.114838\n",
    "0.086432"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-23T18:22:09.943651Z",
     "iopub.status.busy": "2020-08-23T18:22:09.938524Z",
     "iopub.status.idle": "2020-08-23T18:23:30.904845Z",
     "shell.execute_reply": "2020-08-23T18:23:30.903756Z"
    },
    "papermill": {
     "duration": 80.99815,
     "end_time": "2020-08-23T18:23:30.905005",
     "exception": false,
     "start_time": "2020-08-23T18:22:09.906855",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing data...\n"
     ]
    }
   ],
   "source": [
    "test[\"text\"] = test[\"text\"].apply(text_preprocessing)\n",
    "\n",
    "## Run preprocessing_for_bert on the test set\n",
    "print('Tokenizing data...')\n",
    "test_inputs, test_masks = preprocessing_for_bert(test.text)\n",
    "\n",
    "# Create the DataLoader for our test set\n",
    "test_dataset = TensorDataset(test_inputs, test_masks)\n",
    "#test_sampler = SequentialSampler(test_dataset)\n",
    "#test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=32)\n",
    "test_dataloader = DataLoader(test_dataset, shuffle=False, batch_size=16)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.013978,
     "end_time": "2020-08-23T18:23:30.934265",
     "exception": false,
     "start_time": "2020-08-23T18:23:30.920287",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Pre-Processing and creating the test data loader on Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-23T18:23:30.971575Z",
     "iopub.status.busy": "2020-08-23T18:23:30.970514Z",
     "iopub.status.idle": "2020-08-23T18:26:00.341441Z",
     "shell.execute_reply": "2020-08-23T18:26:00.340660Z"
    },
    "papermill": {
     "duration": 149.391558,
     "end_time": "2020-08-23T18:26:00.341583",
     "exception": false,
     "start_time": "2020-08-23T18:23:30.950025",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compute predicted probabilities on the test set\n",
    "probs = bert_predict(bert_classifier, test_dataloader)\n",
    "\n",
    "# Get predictions from the probabilities\n",
    "#threshold = 0.5. ## Change depending on the accuracy you need\n",
    "#preds = np.where(probs[:, 1] > threshold, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-23T18:26:00.381220Z",
     "iopub.status.busy": "2020-08-23T18:26:00.379920Z",
     "iopub.status.idle": "2020-08-23T18:26:00.405258Z",
     "shell.execute_reply": "2020-08-23T18:26:00.405902Z"
    },
    "papermill": {
     "duration": 0.049597,
     "end_time": "2020-08-23T18:26:00.406063",
     "exception": false,
     "start_time": "2020-08-23T18:26:00.356466",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Computer Science</th>\n",
       "      <th>Physics</th>\n",
       "      <th>Mathematics</th>\n",
       "      <th>Statistics</th>\n",
       "      <th>Quantitative Biology</th>\n",
       "      <th>Quantitative Finance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.196693</td>\n",
       "      <td>0.007180</td>\n",
       "      <td>0.063661</td>\n",
       "      <td>0.982799</td>\n",
       "      <td>0.005730</td>\n",
       "      <td>0.005534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.003106</td>\n",
       "      <td>0.991165</td>\n",
       "      <td>0.003372</td>\n",
       "      <td>0.001508</td>\n",
       "      <td>0.003753</td>\n",
       "      <td>0.005436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.993084</td>\n",
       "      <td>0.012771</td>\n",
       "      <td>0.010991</td>\n",
       "      <td>0.010410</td>\n",
       "      <td>0.003352</td>\n",
       "      <td>0.004531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002920</td>\n",
       "      <td>0.990944</td>\n",
       "      <td>0.003485</td>\n",
       "      <td>0.001453</td>\n",
       "      <td>0.003869</td>\n",
       "      <td>0.005164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.993248</td>\n",
       "      <td>0.012382</td>\n",
       "      <td>0.016681</td>\n",
       "      <td>0.008683</td>\n",
       "      <td>0.003370</td>\n",
       "      <td>0.004906</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Computer Science   Physics  Mathematics  Statistics  Quantitative Biology  \\\n",
       "0          0.196693  0.007180     0.063661    0.982799              0.005730   \n",
       "1          0.003106  0.991165     0.003372    0.001508              0.003753   \n",
       "2          0.993084  0.012771     0.010991    0.010410              0.003352   \n",
       "3          0.002920  0.990944     0.003485    0.001453              0.003869   \n",
       "4          0.993248  0.012382     0.016681    0.008683              0.003370   \n",
       "\n",
       "   Quantitative Finance  \n",
       "0              0.005534  \n",
       "1              0.005436  \n",
       "2              0.004531  \n",
       "3              0.005164  \n",
       "4              0.004906  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame(probs,columns=['Computer Science', 'Physics', 'Mathematics',\n",
    "       'Statistics', 'Quantitative Biology', 'Quantitative Finance'])\n",
    "test[['Computer Science', 'Physics', 'Mathematics',\n",
    "       'Statistics', 'Quantitative Biology', 'Quantitative Finance']]=submission\n",
    "final_sub = test[['Computer Science', 'Physics', 'Mathematics',\n",
    "       'Statistics', 'Quantitative Biology', 'Quantitative Finance']]\n",
    "final_sub.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-23T18:26:00.446234Z",
     "iopub.status.busy": "2020-08-23T18:26:00.445428Z",
     "iopub.status.idle": "2020-08-23T18:26:00.627339Z",
     "shell.execute_reply": "2020-08-23T18:26:00.626598Z"
    },
    "papermill": {
     "duration": 0.202858,
     "end_time": "2020-08-23T18:26:00.627483",
     "exception": false,
     "start_time": "2020-08-23T18:26:00.424625",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_sub.to_csv(\"BertModel_proba.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-23T18:26:00.669703Z",
     "iopub.status.busy": "2020-08-23T18:26:00.668827Z",
     "iopub.status.idle": "2020-08-23T18:26:00.673033Z",
     "shell.execute_reply": "2020-08-23T18:26:00.672418Z"
    },
    "papermill": {
     "duration": 0.029798,
     "end_time": "2020-08-23T18:26:00.673156",
     "exception": false,
     "start_time": "2020-08-23T18:26:00.643358",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def check_thresold(thresold):\n",
    "    sub[\"Computer Science\"] = [1 if n >= thresold else 0 for n in final_sub[\"Computer Science\"]]\n",
    "    sub[\"Physics\"] = [1 if n >= thresold else 0 for n in final_sub[\"Physics\"]]\n",
    "    sub[\"Mathematics\"] = [1 if n >= thresold else 0 for n in final_sub[\"Mathematics\"]]\n",
    "    sub[\"Statistics\"] = [1 if n >= thresold else 0 for n in final_sub[\"Statistics\"]]\n",
    "    sub[\"Quantitative Biology\"] = [1 if n >= thresold else 0 for n in final_sub[\"Quantitative Biology\"]]\n",
    "    sub[\"Quantitative Finance\"] = [1 if n >= thresold else 0 for n in final_sub[\"Quantitative Finance\"]]\n",
    "    \n",
    "    sub.to_csv(\"_bert_{}_hdn30_padd462_split8_text_cleaned1.csv\".format(thresold),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-23T18:26:00.751656Z",
     "iopub.status.busy": "2020-08-23T18:26:00.750695Z",
     "iopub.status.idle": "2020-08-23T18:26:00.784365Z",
     "shell.execute_reply": "2020-08-23T18:26:00.783717Z"
    },
    "papermill": {
     "duration": 0.095919,
     "end_time": "2020-08-23T18:26:00.784496",
     "exception": false,
     "start_time": "2020-08-23T18:26:00.688577",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "check_thresold(0.36)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "papermill": {
   "duration": 5863.712258,
   "end_time": "2020-08-23T18:26:02.607429",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-08-23T16:48:18.895171",
   "version": "2.1.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0c218e47568f47e0b320987e3e539c76": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0e52a2512f31409ab6ba6e443abe2161": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0f5573aba18b48abb046a95c7ce49083": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_0c218e47568f47e0b320987e3e539c76",
       "placeholder": "​",
       "style": "IPY_MODEL_7aa5a85a933b442b9397d7bdee16f23c",
       "value": " 232k/232k [00:00&lt;00:00, 886kB/s]"
      }
     },
     "1945f80ae1c04c24932f188369ae47d1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_5ccf9b97d18a4afdb3bc12a750fb0436",
        "IPY_MODEL_0f5573aba18b48abb046a95c7ce49083"
       ],
       "layout": "IPY_MODEL_5731c3b01dab4bc49c5533081b4c2269"
      }
     },
     "19b23c629bc44ec0b119d6ab0bc13da3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2c8419904b9e4701853774628d9a4b5f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "2ca032f7ee044ca7adb7f25b420907ff": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4354fbf8714345799007f423ab87a895": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "44baa5c9ec644a0aa7544aa51b85185a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5731c3b01dab4bc49c5533081b4c2269": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5ccf9b97d18a4afdb3bc12a750fb0436": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "Downloading: 100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_19b23c629bc44ec0b119d6ab0bc13da3",
       "max": 231508,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_6e77fed719d84ac69bb5ff93586388ad",
       "value": 231508
      }
     },
     "6201d9c6ea6645e096a193cc5d8eaf8d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "Downloading: 100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_44baa5c9ec644a0aa7544aa51b85185a",
       "max": 433,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_a4ae4d82405a40748d5d2915e8fcd1d5",
       "value": 433
      }
     },
     "62421aef889e4629981f0588ec70a594": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_fe345e5549734b0ead000ef672ef9fd2",
       "placeholder": "​",
       "style": "IPY_MODEL_7c0c0f90c6814a4f827c6e4c0ea755c6",
       "value": " 440M/440M [00:13&lt;00:00, 33.3MB/s]"
      }
     },
     "6ba74c62147d4888a8e8fdaddc66a1c5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_701fd326857649d5965d2ce2ad86e4bd",
       "placeholder": "​",
       "style": "IPY_MODEL_4354fbf8714345799007f423ab87a895",
       "value": " 433/433 [00:00&lt;00:00, 1.65kB/s]"
      }
     },
     "6e77fed719d84ac69bb5ff93586388ad": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "701fd326857649d5965d2ce2ad86e4bd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7aa5a85a933b442b9397d7bdee16f23c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "7c0c0f90c6814a4f827c6e4c0ea755c6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "88a0200a9d3940d1857f0838fd66e512": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_b0cea56c4a7d43229c6afebf9365c250",
        "IPY_MODEL_62421aef889e4629981f0588ec70a594"
       ],
       "layout": "IPY_MODEL_89ad497fb8084b6a94639d359cb5cd86"
      }
     },
     "89ad497fb8084b6a94639d359cb5cd86": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a4ae4d82405a40748d5d2915e8fcd1d5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "b0cea56c4a7d43229c6afebf9365c250": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "Downloading: 100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_0e52a2512f31409ab6ba6e443abe2161",
       "max": 440473133,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_2c8419904b9e4701853774628d9a4b5f",
       "value": 440473133
      }
     },
     "eb708fa4e5fa4ab39d18ff30bf66f3fd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_6201d9c6ea6645e096a193cc5d8eaf8d",
        "IPY_MODEL_6ba74c62147d4888a8e8fdaddc66a1c5"
       ],
       "layout": "IPY_MODEL_2ca032f7ee044ca7adb7f25b420907ff"
      }
     },
     "fe345e5549734b0ead000ef672ef9fd2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
